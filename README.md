Исходное видео приводится к размеру 320 на 240 пикселей и разбивается на кадры.
После этого создается массив кадров. Далее сравниваются соседние кадры. Если сумма квадратов разностей пикселей превышает пороговое значение, то это означает смену сцены. После чего для предыдущей сцены запускается функция backgr. В ней для каждого пикселя берется массив значений из каждого кадра сцены и применяется кластеризация с помощью алгоритма dbscan из библиотеки sklearn.cluster. Далее берется наиболее распространенный кластер и его усредненное значение добавляется в возвращаемое изображение. Это позволяет убрать из изображения движущиеся объекты. Если же пиклель кластеризован, то он выделяется зеленой маской.
После прохода по всем кадрам полученные изображения для каждой сцены сохраняются в отдельной папке. Далее эти изображения сравниваются для поиска одинаковых сцен. После чего из полученных кадров собирается видео, где движущиеся объекты выделены зеленым, и на каждом кадре присутствует номер локации, к которой он относится. Папка с временными файлами удаляется.
